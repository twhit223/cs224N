{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "import fileinput\n",
    "import numpy as np\n",
    "import gc\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('glove.840B.300d.txt'):\n",
    "    if not os.path.exists('glove.840B.300d.zip'):\n",
    "        print('downloading GloVe')\n",
    "        urllib.request.urlretrieve(\"http://nlp.stanford.edu/data/glove.840B.300d.zip\", \"glove.840B.300d.zip\")\n",
    "    zip = ZipFile('glove.840B.300d.zip')\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train, dev, test splits\n",
      "Building vocabulary\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import fileinput\n",
    "import numpy as np\n",
    "from cove import MTLSTM\n",
    "\n",
    "inputs = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "answers = data.Field(sequential=False)\n",
    "\n",
    "print('Generating train, dev, test splits')\n",
    "train, dev, test = datasets.SNLI.splits(inputs, answers)\n",
    "\n",
    "print('Building vocabulary')\n",
    "inputs.build_vocab(train, dev, test)\n",
    "\n",
    "g = GloVe(name='840B', dim=300)\n",
    "gc.collect()\n",
    "inputs.vocab.load_vectors(vectors=g)\n",
    "gc.collect()\n",
    "\n",
    "answers.build_vocab(train)\n",
    "\n",
    "model = MTLSTM(n_vocab=len(inputs.vocab), vectors=inputs.vocab.vectors)\n",
    "model.cuda(0)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "            (train, dev, test), batch_size=100, device=0)\n",
    "\n",
    "train_iter.init_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# To prevent Tensorflow from being greedy and allocating all GPU memory for itself\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "# Loading loding saved Keras CoVe model\n",
    "cove_model = load_model('Keras_CoVe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Keras CoVe prediction with Pytorch CoVe\n",
      "abs error per dim:2.4579888586353267e-08\n"
     ]
    }
   ],
   "source": [
    "TOTAL_NUM_TEST_SENTENCE = 10000\n",
    "print('Comparing Keras CoVe prediction with Pytorch CoVe')\n",
    "abs_error_per_dim = 0\n",
    "total_num_of_dim = 0\n",
    "num_test_sentence = 0\n",
    "model.train()\n",
    "for batch_idx, batch in enumerate(train_iter):\n",
    "    if num_test_sentence > TOTAL_NUM_TEST_SENTENCE:\n",
    "        # It takes a long time to run through all examples hence restricting the test set \n",
    "        break\n",
    "    cove_premise = model(*batch.premise)\n",
    "    #cove_hypothesis = model(*batch.hypothesis)\n",
    "    sentence_sparse_vector = batch.premise[0].data.cpu().numpy()\n",
    "    for i in range(len(sentence_sparse_vector)):\n",
    "        sentence = sentence_sparse_vector[i]\n",
    "        sentence_glove = []\n",
    "        for word in sentence:\n",
    "            sentence_glove.append(inputs.vocab.vectors[word].numpy())\n",
    "        sentence_glove = np.expand_dims(np.array(sentence_glove),0)\n",
    "        if np.any(np.sum(sentence_glove,axis=2)==0):\n",
    "            break\n",
    "        keras_cove_sentence = cove_model.predict(sentence_glove)\n",
    "        keras_cove_sentence = np.squeeze(keras_cove_sentence,0)\n",
    "        pytorch_cove_sentence = cove_premise.data.cpu().numpy()[i]\n",
    "\n",
    "        abs_error_per_dim+=np.sum(np.abs(keras_cove_sentence - pytorch_cove_sentence))\n",
    "        total_num_of_dim+=np.prod(sentence_glove.shape)\n",
    "        num_test_sentence+=1\n",
    "abs_error_per_dim/=total_num_of_dim\n",
    "print('abs error per dim:'+str(abs_error_per_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
